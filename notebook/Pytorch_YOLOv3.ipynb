{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "coTnfkjuKEeE",
        "hH0HBSj7KQ9s",
        "OYGtQIlNwiMK",
        "S2kr3R_lOIvB",
        "WHFow8_cwC29",
        "bGyYwyzpwIjN",
        "yu6_GtVZRgI4",
        "6el9H2lAxA3o",
        "NJqN21X6jGAH",
        "g3-sfFtSkNTv",
        "Kp5eUQYNdh-D"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install"
      ],
      "metadata": {
        "id": "coTnfkjuKEeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets\n",
        "!pip install -q albumentations"
      ],
      "metadata": {
        "id": "Rw2EYMbqKHYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Env"
      ],
      "metadata": {
        "id": "hH0HBSj7KQ9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn import Conv2d, BatchNorm2d, Identity, LeakyReLU, Upsample"
      ],
      "metadata": {
        "id": "4pjAHL9wKOGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from einops import einsum, rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce"
      ],
      "metadata": {
        "id": "zVxKyLY8NCXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "matplotlib.rcParams['lines.linewidth']=2\n",
        "\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf')"
      ],
      "metadata": {
        "id": "icVzB-mrLLuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed=42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "torch.backends.cudnn.deterministic=True\n",
        "torch.backends.cudnn.benmark=False\n",
        "torch.use_deterministic_algorithms(True)\n",
        "\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "CwNm9SbNOKpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_from_disk\n",
        "from datasets.features import Image as ImageFeature\n",
        "\n",
        "import albumentations as A"
      ],
      "metadata": {
        "id": "iO1DBIFZOHx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global"
      ],
      "metadata": {
        "id": "OYGtQIlNwiMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anchors=[[[0.28, 0.22], [0.38, 0.48], [0.9, 0.78]],\n",
        "         [[0.07, 0.15], [0.15, 0.11], [0.14, 0.29]],\n",
        "         [[0.02, 0.03], [0.04, 0.07], [0.08, 0.06]]]"
      ],
      "metadata": {
        "id": "8kYjVNHOwlxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingestor"
      ],
      "metadata": {
        "id": "S2kr3R_lOIvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from datasets import concatenate_datasets, DatasetDict\n",
        "\n",
        "class Ingestor:\n",
        "    def __init__(self, save_dir='data', dataset_name='visual-layer/oxford-iiit-pet-vl-enriched'):\n",
        "        self.save_dir=save_dir\n",
        "        self.dataset_name=dataset_name\n",
        "\n",
        "    def create_dataset(self, train_size=0.9):\n",
        "        columns=['image','label_bbox_enriched']\n",
        "        dataset = load_dataset(self.dataset_name).select_columns(columns).cast_column('image', ImageFeature(mode='RGB'))\n",
        "        dataset=concatenate_datasets([dataset['train'],dataset['test']])\n",
        "\n",
        "        tmp=dataset.train_test_split(train_size=train_size)\n",
        "        self.dataset=DatasetDict()\n",
        "        self.dataset['train']=tmp.pop('train')\n",
        "        tmp=tmp['test'].train_test_split(train_size=0.5)\n",
        "        self.dataset['validation']=tmp.pop('train')\n",
        "        self.dataset['test']=tmp.pop('test')\n",
        "\n",
        "        self.dataset=self.dataset.map(self.preprocess, batched=True, batch_size=1024, remove_columns=['label_bbox_enriched'])\n",
        "        self.dataset.save_to_disk(self.save_dir)\n",
        "\n",
        "        return self.dataset\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(batch):\n",
        "        target=[x if x is not None else [] for x in batch['label_bbox_enriched']]\n",
        "        return {'label_bbox': target}\n",
        "\n",
        "    def create_label_mapping(self):\n",
        "        labels={}\n",
        "        for split in ['train', 'validation', 'test']:\n",
        "            for sample in self.dataset[split]['label_bbox']:\n",
        "                for box in sample:\n",
        "                    label=box['label']\n",
        "                    if label in labels.keys():\n",
        "                        labels[label]+=1\n",
        "                    else:\n",
        "                        labels[label]=1\n",
        "\n",
        "        labels=sorted(labels.items(), key=lambda x: -x[1])\n",
        "        labels={x[0]:x[1] for x in labels}\n",
        "        label_to_id = {label:id for id, label in enumerate(labels.keys())}\n",
        "        id_to_label = {id:label for id,label in enumerate(labels.keys())}\n",
        "\n",
        "        with open(self.save_dir+'/label_count.json', 'w') as file:\n",
        "            json.dump(labels, file, indent=4)\n",
        "\n",
        "        with open(self.save_dir+'/label_to_id.json', 'w') as file:\n",
        "            json.dump(label_to_id, file, indent=4)\n",
        "\n",
        "        with open(self.save_dir+'/id_to_label.json', 'w') as file:\n",
        "            json.dump(id_to_label, file, indent=4)\n",
        "\n",
        "\n",
        "if os.path.exists('data')==False:\n",
        "    tmp=Ingestor()\n",
        "    tmp.create_dataset()\n",
        "    tmp.create_label_mapping()"
      ],
      "metadata": {
        "id": "7u2P2if6P_7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('data/label_count.json', 'r') as file:\n",
        "    labels=json.load(file)\n",
        "\n",
        "labels"
      ],
      "metadata": {
        "id": "bkGvTOTLcbZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data module"
      ],
      "metadata": {
        "id": "iBY5tTFRZwI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from torch.utils.data import DataLoader\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "class Preprocessor:\n",
        "    def __init__(self):\n",
        "        self.test_transform = A.Compose(\n",
        "            [\n",
        "                A.LongestMaxSize(max_size=224),\n",
        "                A.PadIfNeeded(min_height=224,min_width=224, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
        "                A.Normalize(mean=[0,0,0], std=[1,1,1], max_pixel_value=255),\n",
        "                ToTensorV2()\n",
        "            ],\n",
        "            bbox_params=A.BboxParams(\n",
        "                format='coco',\n",
        "                min_visibility=0.4,\n",
        "                label_fields=['labels']\n",
        "            )\n",
        "        )\n",
        "        self.train_transform = A.Compose(\n",
        "            [\n",
        "                A.LongestMaxSize(max_size=224),\n",
        "                A.PadIfNeeded(min_height=224,min_width=224, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
        "                A.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5, p=0.5),\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.Normalize(mean=[0,0,0], std=[1,1,1], max_pixel_value=255),\n",
        "                ToTensorV2()\n",
        "            ],\n",
        "            bbox_params=A.BboxParams(\n",
        "                format='coco',\n",
        "                min_visibility=0.4,\n",
        "                label_fields=['labels']\n",
        "            )\n",
        "        )\n",
        "\n",
        "class Collator:\n",
        "    def __init__(self, label_to_id):\n",
        "        self.anchors=np.array(anchors)\n",
        "        self.image_size=224\n",
        "        self.num_scale=3\n",
        "        self.num_anchors_per_scale=3\n",
        "        self.grid_sizes=[self.image_size//32, self.image_size//16, self.image_size//8]\n",
        "        self.num_classes=208\n",
        "        self.preprocessor=Preprocessor()\n",
        "        self.transform_fn=self.preprocessor.train_transform\n",
        "        self.label_to_id=label_to_id\n",
        "\n",
        "    def set_mode(self, split):\n",
        "        if split=='train':\n",
        "            self.transform_fn=self.preprocessor.train_transform\n",
        "        else:\n",
        "            self.transform_fn=self.preprocessor.test_transform\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        images=[]\n",
        "        target=[np.zeros([len(batch), self.num_anchors_per_scale, grid_size,grid_size, 6], dtype='float32') for grid_size in self.grid_sizes]\n",
        "        for batch_idx, sample in enumerate(batch):\n",
        "            image = sample['image']\n",
        "            bboxes = [i['bbox'] for i in sample['label_bbox']]\n",
        "            labels = [i['label'] for i in sample['label_bbox']]\n",
        "            processed = self.transform_fn(image=image, bboxes=bboxes, labels=labels)\n",
        "            image, bboxes, labels = processed['image'], processed['bboxes'], processed['labels']\n",
        "            images.append(image)\n",
        "\n",
        "            for box, label in zip(bboxes, labels):\n",
        "                box=self.coco_to_yolo_format(box)\n",
        "                for scale_idx, grid_size in enumerate(self.grid_sizes):\n",
        "                    cell_size = self.image_size/grid_size\n",
        "                    i=int(box[1]/cell_size)\n",
        "                    j=int(box[0]/cell_size)\n",
        "                    ious=self.anchor_iou(self.anchors[scale_idx], box)\n",
        "                    selected_anchor_idx=np.argmax(ious)\n",
        "                    selected_anchor = self.anchors[scale_idx][selected_anchor_idx]\n",
        "\n",
        "                    x = (box[0]-j*cell_size)/cell_size\n",
        "                    y = (box[1]-i*cell_size)/cell_size\n",
        "\n",
        "                    # real_w = exp(pred_w)*anchor_w*image_size\n",
        "                    # real_h = exp(pred_h)*anchor_h*image_size\n",
        "                    w = np.log(box[2]/selected_anchor[0]/self.image_size)\n",
        "                    h = np.log(box[3]/selected_anchor[1]/self.image_size)\n",
        "\n",
        "                    target[scale_idx][batch_idx, selected_anchor_idx, i, j,0]= 1\n",
        "                    target[scale_idx][batch_idx, selected_anchor_idx, i, j,1:5] = x,y,w,h\n",
        "                    target[scale_idx][batch_idx, selected_anchor_idx, i, j, 5] = self.label_to_id[label]\n",
        "\n",
        "        images=torch.stack(images, dim=0)\n",
        "        target=[torch.tensor(i) for i in target]\n",
        "        return images, target\n",
        "\n",
        "    def coco_to_yolo_format(self,box):\n",
        "        x,y,w, h = box\n",
        "\n",
        "        x_center = x+w/2\n",
        "        y_center = y+h/2\n",
        "\n",
        "        return x_center,y_center,w,h\n",
        "\n",
        "    @staticmethod\n",
        "    def anchor_iou(anchors, box):\n",
        "        anchors_area = anchors[..., 0]*anchors[..., 1]\n",
        "        box_area = box[0]*box[1]\n",
        "        intersection = np.minimum(anchors[..., 0], box[0]) * np.minimum(anchors[..., 1], box[1])\n",
        "        iou = intersection/(anchors_area+box_area-intersection)\n",
        "        return iou\n",
        "\n",
        "class DataModule:\n",
        "    def __init__(self, data_dir='data'):\n",
        "        self.dataset=load_from_disk(data_dir).with_format(\"numpy\")\n",
        "        with open(data_dir+'/label_to_id.json') as file:\n",
        "            self.label_to_id = json.load(file)\n",
        "        with open(data_dir+'/id_to_label.json') as file:\n",
        "            self.id_to_label = json.load(file)\n",
        "\n",
        "        self.collator=Collator(self.label_to_id)\n",
        "\n",
        "    def get_data_loader(self,split, batch_size=4, shuffle=False):\n",
        "        self.collator.set_mode(split)\n",
        "        return DataLoader(self.dataset[split], batch_size=batch_size, shuffle=shuffle, drop_last=True, collate_fn=self.collator)\n",
        "\n",
        "tmp=DataModule('data')\n",
        "loader=tmp.get_data_loader('test')\n",
        "test_batch=next(iter(loader))\n",
        "print(test_batch[0].shape)\n",
        "for x in test_batch[1]:\n",
        "    print(x.shape)"
      ],
      "metadata": {
        "id": "pfYWjc0DZ0hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot"
      ],
      "metadata": {
        "id": "WHFow8_cwC29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "def draw_boxes(image, annotations):\n",
        "    colors = {}\n",
        "    image.save('input.png')\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    for annotation in annotations:\n",
        "        x_min, y_min, width, height = annotation['bbox']\n",
        "        x_max=x_min+width\n",
        "        y_max=y_min+height\n",
        "        box=[x_min, y_min, x_max,y_max]\n",
        "        label = annotation['label']\n",
        "\n",
        "        if label not in colors:\n",
        "            colors[label] = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
        "\n",
        "        color = colors[label]\n",
        "        draw.rectangle(box, outline=color, width=2)\n",
        "\n",
        "        text_position = (box[0], box[1] - 10)\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "        text_bbox = font.getbbox(label)\n",
        "        text_width = text_bbox[2] - text_bbox[0]\n",
        "        text_height = text_bbox[3] - text_bbox[1]\n",
        "\n",
        "        draw.rectangle(\n",
        "            [text_position, (text_position[0] + text_width, text_position[1] + text_height)],\n",
        "            fill=color\n",
        "        )\n",
        "        draw.text(text_position, label, fill=(255, 255, 255), font=font)\n",
        "\n",
        "    image.save('target.png')\n",
        "    return image\n",
        "\n",
        "data=tmp.dataset['validation'][0]\n",
        "result_image = draw_boxes(Image.fromarray(data['image']), data['label_bbox'])\n",
        "result_image"
      ],
      "metadata": {
        "id": "S7QUjq1swH8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture"
      ],
      "metadata": {
        "id": "bGyYwyzpwIjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0, use_bn=True):\n",
        "        super().__init__()\n",
        "        self.net=nn.Sequential(\n",
        "            Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=not use_bn),\n",
        "            BatchNorm2d(out_channels) if use_bn else Identity(),\n",
        "            LeakyReLU(negative_slope=0.1) if use_bn else Identity()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "tmp=CNNBlock(3,6)\n",
        "x=torch.rand(7,3,224,224)\n",
        "tmp(x).shape"
      ],
      "metadata": {
        "id": "dgAahfJKwWnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, use_residual=True, num_repeats=1):\n",
        "        super().__init__()\n",
        "        layers=[]\n",
        "        for _ in range(num_repeats):\n",
        "            block=nn.Sequential(\n",
        "                Conv2d(in_channels, in_channels//2, kernel_size=1),\n",
        "                BatchNorm2d(in_channels//2),\n",
        "                LeakyReLU(negative_slope=0.1),\n",
        "                Conv2d(in_channels//2, in_channels, kernel_size=1),\n",
        "                BatchNorm2d(in_channels),\n",
        "                LeakyReLU(negative_slope=0.1)\n",
        "            )\n",
        "            layers.append(block)\n",
        "\n",
        "        self.net=nn.ModuleList(layers)\n",
        "        self.use_residual=use_residual\n",
        "        self.num_repeats=num_repeats\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.net:\n",
        "            x = x + layer(x) if self.use_residual else layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "tmp=ResidualBlock(3, num_repeats=3)\n",
        "x=torch.rand(7,3,224,224)\n",
        "tmp(x).shape"
      ],
      "metadata": {
        "id": "5tKx0R6lxwze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScalePrediction(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes, num_anchors_per_scale):\n",
        "        super().__init__()\n",
        "        self.net=nn.Sequential(\n",
        "            Conv2d(in_channels, 2*in_channels, kernel_size=3, padding=1),\n",
        "            BatchNorm2d(2*in_channels),\n",
        "            LeakyReLU(negative_slope=0.1),\n",
        "            Conv2d(2*in_channels, (num_classes+5)*num_anchors_per_scale, kernel_size=1),\n",
        "            Rearrange('b (a c) w h -> b a w h c', c=num_classes+5)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "tmp=ScalePrediction(3,208,3)\n",
        "x=torch.rand(7,3,224,224)\n",
        "tmp(x).shape"
      ],
      "metadata": {
        "id": "O2-UK80bz6qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Darknet(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes, num_anchors_per_scale=3):\n",
        "        super().__init__()\n",
        "        self.net=nn.ModuleList([\n",
        "            CNNBlock(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            CNNBlock(in_channels=32, out_channels=64,kernel_size=3, stride=2, padding=1),\n",
        "            ResidualBlock(in_channels=64, num_repeats=1),\n",
        "\n",
        "            CNNBlock(in_channels=64, out_channels=128,kernel_size=3, stride=2, padding=1),\n",
        "            ResidualBlock(in_channels=128, num_repeats=1),\n",
        "\n",
        "            CNNBlock(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1),\n",
        "            ResidualBlock(in_channels=256, num_repeats=2),\n",
        "\n",
        "            CNNBlock(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=1),\n",
        "            ResidualBlock(in_channels=512, num_repeats=2),\n",
        "\n",
        "            CNNBlock(in_channels=512, out_channels=1024, kernel_size=3, stride=2, padding=1),\n",
        "            ResidualBlock(in_channels=1024, num_repeats=1),\n",
        "\n",
        "            CNNBlock(in_channels=1024, out_channels=512, kernel_size=1),\n",
        "            CNNBlock(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n",
        "            ResidualBlock(in_channels=1024, use_residual=False, num_repeats=1),\n",
        "\n",
        "            CNNBlock(in_channels=1024, out_channels=512, kernel_size=1),\n",
        "            ScalePrediction(in_channels=512, num_classes=num_classes, num_anchors_per_scale=num_anchors_per_scale),\n",
        "\n",
        "            CNNBlock(in_channels=512, out_channels=256, kernel_size=1),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "\n",
        "            CNNBlock(in_channels=256+512, out_channels=256, kernel_size=1),\n",
        "            CNNBlock(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            ResidualBlock(in_channels=512, use_residual=False, num_repeats=1),\n",
        "\n",
        "            CNNBlock(in_channels=512, out_channels=256, kernel_size=1),\n",
        "            ScalePrediction(in_channels=256, num_classes=num_classes, num_anchors_per_scale=num_anchors_per_scale),\n",
        "\n",
        "            CNNBlock(in_channels=256, out_channels=128, kernel_size=1),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "\n",
        "            CNNBlock(in_channels=128+256, out_channels=128, kernel_size=1),\n",
        "            CNNBlock(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            ResidualBlock(in_channels=256, use_residual=False, num_repeats=1),\n",
        "\n",
        "            CNNBlock(in_channels=256, out_channels=128, kernel_size=1),\n",
        "            ScalePrediction(in_channels=128, num_classes=num_classes, num_anchors_per_scale=num_anchors_per_scale),\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs=[]\n",
        "        route_connections=[]\n",
        "        for idx, layer in enumerate(self.net):\n",
        "            if isinstance(layer, ScalePrediction):\n",
        "                outputs.append(layer(x))\n",
        "                continue\n",
        "            x=layer(x)\n",
        "            if isinstance(layer, ResidualBlock) and layer.num_repeats==2:\n",
        "                route_connections.append(x)\n",
        "            elif isinstance(layer, nn.Upsample):\n",
        "                x=torch.cat([x, route_connections[-1]], dim=1)\n",
        "                route_connections.pop()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "tmp=Darknet(3,208)\n",
        "x=torch.rand(7,3,224,224)\n",
        "out=tmp(x)\n",
        "for i in out:\n",
        "    print(i.shape)"
      ],
      "metadata": {
        "id": "t5R7O4NV2EnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YoloMimic(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.net_1 = Conv2d(in_channels, (num_classes+5)*3, kernel_size=3, stride=32, padding=1)\n",
        "        self.net_2 = Conv2d(in_channels, (num_classes+5)*3, kernel_size=3, stride=16, padding=1)\n",
        "        self.net_3 = Conv2d(in_channels, (num_classes+5)*3, kernel_size=3, stride=8, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.net_1(x).reshape([-1, 3, 7, 7, self.num_classes+5])\n",
        "        x2 = self.net_2(x).reshape([-1, 3, 14, 14, self.num_classes+5])\n",
        "        x3 = self.net_3(x).reshape([-1, 3, 28, 28, self.num_classes+5])\n",
        "\n",
        "        return x1, x2, x3\n",
        "\n",
        "tmp=YoloMimic(3,208)\n",
        "x=torch.rand(7,3,224,224)\n",
        "out=tmp(x)\n",
        "for i in out:\n",
        "    print(i.shape)"
      ],
      "metadata": {
        "id": "iUg7rHO3hTs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Postprocess"
      ],
      "metadata": {
        "id": "yu6_GtVZRgI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_prediction(predictions, anchors, grid_sizes):\n",
        "    # prediction= list, scale, batch_size, num_anchors, w, h, num_classes+6\n",
        "    refined=[]\n",
        "    for scale_idx, scale in enumerate(predictions):\n",
        "        for idx, anchor in enumerate(anchors[scale_idx]):\n",
        "            pred=scale[:, idx]\n",
        "\n",
        "            obj=F.sigmoid(pred[..., 0:1])\n",
        "            x=F.sigmoid(pred[..., 1:2])+torch.arange(grid_sizes[scale_idx]).view(1, -1).expand(grid_sizes[scale_idx], -1).unsqueeze(-1)\n",
        "            y=F.sigmoid(pred[..., 2:3])+torch.arange(grid_sizes[scale_idx]).view(-1,1).expand(-1, grid_sizes[scale_idx]).unsqueeze(-1)\n",
        "            wh=torch.exp(pred[..., 3:5])*anchor\n",
        "            prob, cls=torch.max(pred[..., 5:].softmax(dim=-1), dim=-1, keepdims=True)\n",
        "\n",
        "            pred=torch.cat([obj, x, y, wh, cls, prob],dim=-1)\n",
        "            refined.append(pred)\n",
        "\n",
        "    return refined\n",
        "\n",
        "res=format_prediction(out, torch.tensor(anchors), [7,14,28])\n",
        "for i in res:\n",
        "    print(i.shape)"
      ],
      "metadata": {
        "id": "078Y1Qw_Rl35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_iou(box1, box2):\n",
        "    x_min=np.maximum(box1[..., 0]-box1[..., 2]/2, box2[..., 0]-box2[..., 2]/2)\n",
        "    x_max=np.minimum(box1[..., 0]+box1[..., 2]/2, box2[..., 0]+box2[..., 2]/2)\n",
        "\n",
        "    y_min=np.maximum(box1[..., 1]-box1[..., 3]/2, box2[..., 1]-box2[..., 3]/2)\n",
        "    y_max=np.minimum(box1[..., 1]+box1[..., 3]/2, box2[..., 1]+box2[..., 3]/2)\n",
        "\n",
        "    intersection = np.maximum(0, x_max-x_min)*np.maximum(0, y_max-y_min)\n",
        "    union = box1[..., 2]*box1[..., 3]+box2[..., 2]*box2[..., 3] - intersection\n",
        "\n",
        "    return intersection / np.maximum(union, 1e-9)\n",
        "\n",
        "def non_max_suppression(predictions, obj_threshold=0.5, iou_threshold=0.5):\n",
        "    filtered_boxes=[[] for _  in range(predictions[0].shape[0])]\n",
        "    for pred in predictions:\n",
        "        for idx, sample in enumerate(pred):\n",
        "            boxes=sample[sample[..., 0]>obj_threshold]\n",
        "            filtered_boxes[idx].extend(boxes)\n",
        "\n",
        "    result=[]\n",
        "    for idx,batch in enumerate(filtered_boxes):\n",
        "        if not batch:\n",
        "            result.append([])\n",
        "            continue\n",
        "\n",
        "        boxes = torch.stack(batch, dim=0)\n",
        "        boxes = boxes[torch.argsort(-boxes[..., 0])]\n",
        "\n",
        "        selected=[]\n",
        "        while len(boxes)>0:\n",
        "            selected.append(boxes[0])\n",
        "            ious=yolo_iou(selected[-1][1:5], boxes[..., 1:5])\n",
        "            boxes = boxes[ious < iou_threshold]\n",
        "\n",
        "        result.append(selected)\n",
        "\n",
        "    return result\n",
        "\n",
        "x=non_max_suppression([i.detach() for i in res])\n",
        "for i in x:\n",
        "    print(len(i))"
      ],
      "metadata": {
        "id": "kBsVuaieLi_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_true_boxes(targets, anchors, grid_sizes):\n",
        "    refined=[]\n",
        "    for scale_idx, scale in enumerate(targets):\n",
        "        for idx, anchor in enumerate(anchors[scale_idx]):\n",
        "            target=scale[:, idx]\n",
        "\n",
        "            obj=target[..., 0:1]\n",
        "            x=target[..., 1:2]+torch.arange(grid_sizes[scale_idx]).view(1, -1).expand(grid_sizes[scale_idx], -1).unsqueeze(-1)\n",
        "            y=target[..., 2:3]+torch.arange(grid_sizes[scale_idx]).view(-1,1).expand(-1, grid_sizes[scale_idx]).unsqueeze(-1)\n",
        "            wh=torch.exp(target[..., 3:5])*anchor\n",
        "            cls=target[..., 5:]\n",
        "\n",
        "            target=torch.cat([obj, x, y, wh, cls],dim=-1)\n",
        "            refined.append(target)\n",
        "\n",
        "    result=[[] for _ in range(targets[0].shape[0])]\n",
        "    for target in refined:\n",
        "        for idx, sample in enumerate(target):\n",
        "            result[idx].extend(sample[sample[..., 0]==1])\n",
        "\n",
        "    return result\n",
        "    # list batch box(obj, x,y,w,h,cls)\n",
        "\n",
        "get_true_boxes(test_batch[1], torch.tensor(anchors), [7,14,28])"
      ],
      "metadata": {
        "id": "1bccavRrMDzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAP and MAR"
      ],
      "metadata": {
        "id": "6el9H2lAxA3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mimic_output(batch_size, grid_sizes, num_classes):\n",
        "    outputs=[]\n",
        "    for grid_size in grid_sizes:\n",
        "        obj=torch.rand(batch_size,3, grid_size, grid_size, 1)\n",
        "        x=torch.rand(batch_size,3, grid_size, grid_size, 1)\n",
        "        y=torch.rand(batch_size,3, grid_size, grid_size, 1)\n",
        "        w=torch.rand(batch_size,3, grid_size, grid_size, 1)\n",
        "        h=torch.rand(batch_size,3, grid_size, grid_size, 1)\n",
        "        cls=torch.rand(batch_size, 3, grid_size, grid_size, num_classes)\n",
        "        o=torch.cat([obj,x,y,w,h,cls], dim=-1)\n",
        "        outputs.append(o)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "mimic=mimic_output(4,[7,14,28],208)\n",
        "for i in mimic:\n",
        "    print(i.shape)"
      ],
      "metadata": {
        "id": "Bd2FXGG5c46u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MAPR:\n",
        "    def __init__(self, anchors, grid_sizes=None, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps=eps\n",
        "        self.num_classes=208\n",
        "        self.anchors=torch.tensor(anchors)\n",
        "        self.grid_sizes=grid_sizes\n",
        "\n",
        "        self.iou_thresholds=[0.0, 0.075]\n",
        "\n",
        "        self.TP_FP=[[] for _ in range(self.num_classes)]\n",
        "        self.TP_FN=np.zeros([self.num_classes])\n",
        "\n",
        "    def box_count(self, pred_boxes,true_boxes):\n",
        "        for instance_pred_boxes, instance_true_boxes in zip(pred_boxes, true_boxes):\n",
        "            if len(instance_true_boxes)==0:\n",
        "                   continue\n",
        "\n",
        "            instance_pred_boxes = sorted(instance_pred_boxes, key=lambda x:x[5], reverse=True)\n",
        "\n",
        "            for true_box in instance_true_boxes:\n",
        "                self.TP_FN[int(true_box[4])]+=1\n",
        "\n",
        "            matched=[False for _ in range(len(instance_true_boxes))]\n",
        "            instance_pred_boxes = torch.stack(instance_pred_boxes, dim=0)\n",
        "            instance_true_boxes = torch.stack(instance_true_boxes, dim=0)\n",
        "            ious=yolo_iou(instance_pred_boxes.unsqueeze(1), instance_true_boxes.unsqueeze(0))\n",
        "            best_scores,best_indices = torch.max(ious, dim=1)\n",
        "\n",
        "            for idx, (best_score, best_idx) in enumerate(zip(best_scores, best_indices)):\n",
        "                pred_box=instance_pred_boxes[idx]\n",
        "                if matched[best_idx]==False:\n",
        "                    self.TP_FP[int(pred_box[4])].append([best_score, 'TP'])\n",
        "                    matched[best_idx]=True\n",
        "                else:\n",
        "                    self.TP_FP[int(pred_box[4])].append([best_score, 'FP'])\n",
        "\n",
        "    def reset(self):\n",
        "        self.TP_FP=[[] for _ in range(self.num_classes)]\n",
        "        self.TP_FN=np.zeros([self.num_classes])\n",
        "\n",
        "    def update(self, preds, targets):\n",
        "        true_boxes=get_true_boxes(targets, self.anchors, self.grid_sizes)\n",
        "        preds=format_prediction(preds, self.anchors, self.grid_sizes)\n",
        "        pred_boxes=non_max_suppression(preds, iou_threshold=0.05, obj_threshold=0.05)\n",
        "\n",
        "        self.box_count(pred_boxes,true_boxes)\n",
        "\n",
        "    def compute(self):\n",
        "        mAP=np.zeros([len(self.iou_thresholds), self.num_classes])\n",
        "        res={}\n",
        "        for cls_idx, P in enumerate(self.TP_FP):\n",
        "            for threshold_idx, threshold in enumerate(self.iou_thresholds):\n",
        "                P=sorted(P, key= lambda x: x[0], reverse=True)\n",
        "                TP=[1 if threshold<=x[0] and x[1]=='TP' else 0 for x in P]\n",
        "                FP=[1 if threshold>x[0] and x[1]=='FP' else 0 for x in P]\n",
        "                TP_cumsum=torch.cumsum(torch.tensor(TP),dim=0)\n",
        "                FP_cumsum=torch.cumsum(torch.tensor(FP),dim=0)\n",
        "                recall=TP_cumsum/(self.TP_FN[cls_idx]+self.eps)\n",
        "                recall=torch.cat([torch.tensor([0]), recall])\n",
        "\n",
        "                precision=torch.divide(TP_cumsum, TP_cumsum+FP_cumsum+self.eps)\n",
        "                precision=torch.cat([torch.tensor([1]), precision])\n",
        "\n",
        "                mAP[threshold_idx][cls_idx]=torch.trapz(precision, recall)\n",
        "\n",
        "            res['mAP@'+str(threshold)]=sum(mAP[threshold_idx])/len(mAP[threshold_idx])\n",
        "\n",
        "        return res\n",
        "\n",
        "tmp=MAPR(anchors, [7,14,28])\n",
        "tmp.update(mimic,test_batch[1])\n",
        "tmp.compute()"
      ],
      "metadata": {
        "id": "Q9tzegdRZnr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric"
      ],
      "metadata": {
        "id": "NJqN21X6jGAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Metric:\n",
        "    def __init__(self):\n",
        "        self.metric={}\n",
        "        self.current_metric={}\n",
        "        # self.mAP=MAPR(anchors, [7,14,28])\n",
        "\n",
        "    def update(self, batch_metric, preds=None, targets=None):\n",
        "        for key,value in batch_metric.items():\n",
        "            if key not in self.current_metric.keys():\n",
        "                self.current_metric[key]=[]\n",
        "\n",
        "            self.current_metric[key].append(value)\n",
        "\n",
        "        # if preds is not None and targets is not None:\n",
        "        #     self.mAP.update(preds, targets)\n",
        "\n",
        "    def finalize(self):\n",
        "        # self.update(self.mAP.compute())\n",
        "        for key, value in self.current_metric.items():\n",
        "            if key not in self.metric.keys():\n",
        "                self.metric[key]=[]\n",
        "            self.metric[key].append(sum(value)/len(value))\n",
        "\n",
        "        self.current_metric={}\n",
        "\n",
        "    def plot(self):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        for key, val in self.metric.items():\n",
        "            plt.plot(val, label=key)\n",
        "\n",
        "        plt.title(\"Metrics per Epoch\")\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Metrics\")\n",
        "        plt.legend()\n",
        "\n",
        "tmp=Metric()\n",
        "for i in range(10):\n",
        "    tmp.update({'loss': i,\n",
        "                'acc': i+1})\n",
        "    tmp.finalize()\n",
        "tmp.plot()"
      ],
      "metadata": {
        "id": "5n8VDHOg27RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss"
      ],
      "metadata": {
        "id": "g3-sfFtSkNTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLOLoss:\n",
        "    def __init__(self):\n",
        "        self.anchors=torch.tensor(anchors)\n",
        "        self.lambda_obj=1\n",
        "        self.lambda_noobj=1\n",
        "        self.lambda_coord=1\n",
        "        self.lambda_class=1\n",
        "\n",
        "        self.mse = torch.nn.MSELoss()\n",
        "        self.bce = torch.nn.BCEWithLogitsLoss()\n",
        "        self.ce = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def __call__(self, preds, targets):\n",
        "        loss=0.0\n",
        "        for pred, target, anchor in zip(preds, targets, self.anchors):\n",
        "            loss=loss+self.single_loss(pred, target, anchor)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def single_loss(self, pred, target, anchors):\n",
        "        obj = target[..., 0]==1\n",
        "        noobj = target[..., 0]==0\n",
        "\n",
        "        # no obj loss\n",
        "        noobj_loss = self.bce(pred[..., 0][noobj], target[..., 0][noobj])\n",
        "\n",
        "        # obj loss\n",
        "        anchors = anchors.reshape(1,3,1,1,2)\n",
        "        pred_boxes = torch.cat([torch.sigmoid(pred[...,1:3]), torch.exp(pred[...,3:5])*anchors], dim=-1)\n",
        "        iou_scores = yolo_iou(pred_boxes[obj].detach(), target[..., 1:5][obj].detach())\n",
        "        obj_loss = self.bce(pred[...,0][obj], iou_scores*target[...,0][obj])\n",
        "\n",
        "        # box loss\n",
        "        pred_boxes = torch.cat([torch.sigmoid(pred[..., 1:3]), pred[..., 3:5]], dim=-1)\n",
        "        true_boxes = torch.cat([target[..., 1:3], target[...,3:5]], axis=-1)\n",
        "        coord_loss = self.mse(pred_boxes[obj], true_boxes[obj])\n",
        "        # class loss\n",
        "        class_loss = self.ce(pred[...,5:][obj], target[..., 5][obj].long())\n",
        "\n",
        "        return self.lambda_noobj*noobj_loss + self.lambda_obj*obj_loss + self.lambda_coord*coord_loss + self.lambda_class*class_loss"
      ],
      "metadata": {
        "id": "bGk8rxcc9hHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Kp5eUQYNdh-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self):\n",
        "        self.data_module = DataModule('data')\n",
        "        self.criterion=YOLOLoss()\n",
        "        self.model=YoloMimic(3,208).to(device)\n",
        "        self.opt=torch.optim.Adam(params = self.model.parameters(), lr=1e-3)\n",
        "        self.metrics=Metric()\n",
        "\n",
        "    def train_step(self, inputs, targets):\n",
        "        inputs = inputs.to(device)\n",
        "        targets = [target.to(device) for target in targets]\n",
        "        preds = self.model(inputs)\n",
        "        loss= self.criterion(preds, targets)\n",
        "\n",
        "        self.opt.zero_grad()\n",
        "        loss.backward()\n",
        "        self.opt.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def val_step(self, inputs, targets):\n",
        "        inputs = inputs.to(device)\n",
        "        targets = [target.to(device) for target in targets]\n",
        "        with torch.no_grad():\n",
        "            preds = self.model(inputs)\n",
        "            loss= self.criterion(preds, targets)\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def evaluate(self, batch_size=32):\n",
        "        mAP=MAPR(anchors, [7,14,28])\n",
        "        test_loader = self.data_module.get_data_loader('test', batch_size=batch_size, shuffle=False)\n",
        "        p_bar = tqdm(test_loader, desc='Evaluation: ')\n",
        "        self.model.eval()\n",
        "        for inputs, targets in p_bar:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = [target.to(device) for target in targets]\n",
        "            with torch.no_grad():\n",
        "                preds = self.model(inputs)\n",
        "                loss= self.criterion(preds, targets).item()\n",
        "\n",
        "            mAP.update(preds, targets)\n",
        "            self.metrics.update({'train_loss': loss})\n",
        "            p_bar.set_postfix(train_loss=loss)\n",
        "\n",
        "        return mAP.compute()\n",
        "\n",
        "    def train(self, num_epochs=1, batch_size=32):\n",
        "        train_loader = self.data_module.get_data_loader('train', batch_size=batch_size, shuffle=True)\n",
        "        val_loader = self.data_module.get_data_loader('validation', batch_size=batch_size, shuffle=False)\n",
        "        for epoch in tqdm(range(num_epochs)):\n",
        "            self.model.train()\n",
        "            p_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}: ')\n",
        "            for inputs, targets in p_bar:\n",
        "                loss=self.train_step(inputs, targets)\n",
        "\n",
        "                self.metrics.update({'train_loss': loss})\n",
        "                p_bar.set_postfix(train_loss=loss)\n",
        "\n",
        "            self.model.eval()\n",
        "            p_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs}: ')\n",
        "            for inputs, targets in p_bar:\n",
        "                loss=self.val_step(inputs, targets)\n",
        "\n",
        "                self.metrics.update({'val_loss': loss})\n",
        "                p_bar.set_postfix(val_loss=loss)\n",
        "\n",
        "            self.metrics.finalize()\n",
        "\n",
        "    def save(self):\n",
        "        torch.save(self.model, 'model.pt')\n",
        "        model_scripted = torch.jit.script(self.model)\n",
        "        model_scripted.save('model_scripted.pt')\n",
        "\n",
        "trainer=Trainer()\n",
        "trainer.train()\n",
        "# tmp.evaluate()"
      ],
      "metadata": {
        "id": "sbSUiUBYvuoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "JXAgOAiWDJ3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "def yolo_to_pascal_voc_format(box):\n",
        "    x1 = box[...,0]-box[...,2]/2\n",
        "    y1 = box[...,1]-box[...,3]/2\n",
        "    x2 = box[...,0]+box[...,2]/2\n",
        "    y2 = box[...,1]+box[...,3]/2\n",
        "\n",
        "    return np.array([x1,y1,x2,y2])\n",
        "\n",
        "class Predictor:\n",
        "    def __init__(self, model, data_dir, anchors, grid_sizes):\n",
        "        self.transform=Preprocessor().test_transform\n",
        "        self.model=model\n",
        "        self.anchors=anchors\n",
        "        self.grid_sizes=grid_sizes\n",
        "        with open(data_dir+'/id_to_label.json') as file:\n",
        "            self.id_to_label = json.load(file)\n",
        "\n",
        "    def inference(self, img):\n",
        "        # img is pil image\n",
        "        input=self.transform(image=np.array(img), labels=[])['image'][None]\n",
        "        with torch.no_grad():\n",
        "            output=self.model(input)\n",
        "        output=format_prediction(output, self.anchors, self.grid_sizes)\n",
        "        boxes=non_max_suppression(output)\n",
        "\n",
        "        img_size=img.size\n",
        "        scale_factor=max(img_size[0], img_size[1])/input.shape[-1]\n",
        "        return self.draw_boxes(img, boxes[0], scale_factor)\n",
        "\n",
        "    def draw_boxes(self, image, boxes, scale_factor):\n",
        "        colors = {}\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        for box in boxes:\n",
        "            box=np.array(box)\n",
        "            label_idx=str(int(box[5]))\n",
        "            label_prob=box[6]\n",
        "            label=self.id_to_label[label_idx]\n",
        "            box=box[1:5]\n",
        "            box=yolo_to_pascal_voc_format(box)\n",
        "            box = [int(coord*scale_factor) for coord in box]\n",
        "            if label not in colors:\n",
        "                colors[label] = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
        "\n",
        "            color = colors[label]\n",
        "            draw.rectangle(box, outline=color, width=2)\n",
        "\n",
        "            text_position = (box[0], box[1] - 10)\n",
        "            font = ImageFont.load_default()\n",
        "\n",
        "            text_bbox = font.getbbox(label)\n",
        "            text_width = text_bbox[2] - text_bbox[0]\n",
        "            text_height = text_bbox[3] - text_bbox[1]\n",
        "\n",
        "            draw.rectangle(\n",
        "                [text_position, (text_position[0] + text_width, text_position[1] + text_height)],\n",
        "                fill=color\n",
        "            )\n",
        "            draw.text(text_position, label+': '+str(round(label_prob*100,2)), fill=(255, 255, 255), font=font)\n",
        "\n",
        "        return image\n",
        "\n",
        "predictor=Predictor(trainer.model, 'data', torch.tensor(anchors), [7,14,28])\n",
        "img=Image.open('input.png')\n",
        "predictor.inference(img)"
      ],
      "metadata": {
        "id": "xP-xsFeVDad3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}